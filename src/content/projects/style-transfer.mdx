---
title: "Real-Time Style Transfer Plugin"
description: "Godot engine plugin applying neural style transfer to viewport textures. Includes training pipeline and C++ integration."
tags: ["c++", "pytorch", "godot", "ml"]
publishedAt: 2024-12-15
featured: true
github: "https://github.com/ethereal-keys/Godot-Style-Transfer"
order: 1
tabs:
  - label: "./overview"
    id: "overview"
  - label: "./demo"
    id: "demo"
  - label: "./technical"
    id: "technical-implementation"
  - label: "./reflections"
    id: "reflections"
---

## Overview

When I first started exploring neural style transfer, I didn't expect to end up
knee deep in Godot's rendering pipeline. But here we are.

The goal was simple: make a game look like a painting in real-time. The execution
was anything but.

## The First Attempt

I started where anyone would: the original Gatys et al. paper. The results were
beautiful. The performance was not.

```python
def style_transfer(content, style, iterations=500):
    # This took 45 seconds per frame
    for i in range(iterations):
        optimize_step(content, style)
    return content
```

45 seconds. Per frame. For a game targeting 60fps, I needed to be roughly
2,700 times faster.

## The Solution

The breakthrough came from Johnson et al.'s feed-forward approach. Instead of
optimizing at runtime, we train a network to perform the transformation in a
single forward pass.

## Demo
 
<YouTubeEmbed videoId="ad-yBz3aguA" title="Style Transfer Demo" />
 
## Technical Implementation

The plugin integrates with Godot's rendering pipeline:

1. Capture viewport texture each frame
2. Pass through PyTorch model via C++ bindings
3. Return stylized texture to viewport
4. Maintain 60fps target
 
<AsciiDiagram title="Pipeline Architecture">
{`+-------------+      +-------------+      +-------------+
|  Viewport   | ---> |  C++ Bind   | ---> |   PyTorch   |
|   Texture   |      |   (GDExt)   |      |    Model    |
+-------------+      +-------------+      +-------------+
       ^                                         |
       |                                         |
       +-----------------------------------------+
                    Stylized Frame`}
</AsciiDiagram>
 
## Reflections

### What Worked
- The feed-forward architecture delivered real-time performance
- C++ integration with Godot was cleaner than expected

<Comic 
  src="https://imgs.xkcd.com/comics/machine_learning.png" 
  alt="XKCD Machine Learning" 
  caption="relevant xkcd as always" 
/>
 
### What I'd Do Differently
- Start with a simpler style transfer model
- Profile GPU memory usage earlier in development

### Future Directions
- Multi-style interpolation
- Video temporal consistency